# Stochastic Gradient Descent and Adam in Non-Stationary Environments

This repository contains the project _Stochastic Gradient Descent and Adam in Non-Stationary Environments_ developed for the CS-439 Optimization for Machine Learning at EPFL. The report can be found in the `report.pdf` file. The `experiments.ipynb` notebook contains the code for the experiment discussed in the report.

Our code was tested with python 3.8 and the latest versions of the following packages:
- numpy
- matplotlib
- seaborn
- torch

Make sure to install them before running the code.

